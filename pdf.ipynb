{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from apikey import apikey\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = apikey\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "directory = 'C:/Users/user/Desktop/AutoGPT/data'\n",
    "\n",
    "def load_doc(directory):\n",
    "    loader = DirectoryLoader(directory)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "documents = load_doc(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_docs(documents, chunk_size=1000, chunk_overlap=20):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs\n",
    "\n",
    "docs = split_docs(documents)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "query_result  = embeddings.embed_query('Hello World')\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "pinecone.init(\n",
    "    api_key='b988fddd-4694-4ed7-ae36-2bc1afadf0b1',\n",
    "    environment='us-west4-gcp'\n",
    ")\n",
    "\n",
    "index_name = 'langchain-demo'\n",
    "\n",
    "index = Pinecone.from_documents(docs,embeddings, index_name = index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='H\\n\\nG\\n\\n,\\n\\nData science provides the language and techniques necessary for understanding and dealing with data. It involves the design, collection, analysis, and interpretation of nu- merical data, with the aim of extracting patterns and other useful information. Machine learning, which is closely related to data science, deals with the design of algorithms and computer resources to learn from data. The organization of the book follows roughly the typical steps in a data science project: Gathering data to gain information about a research question; cleaning, summarization, and visualization of the data; modeling and analysis of the data; translating decisions about the model into decisions and predictions about the re- search question. As this is a mathematics and statistics oriented book, most emphasis will be on modeling and analysis.', metadata={'source': 'C:\\\\Users\\\\user\\\\Desktop\\\\AutoGPT\\\\data\\\\DSML.pdf'}),\n",
       " Document(page_content='The purpose of this book is to provide an accessible, yet comprehensive, account of data science and machine learning. It is intended for anyone interested in gaining a better understanding of the mathematics and statistics that underpin the rich variety of ideas and machine learning algorithms in data science. Our viewpoint is that computer languages come and go, but the underlying key ideas and algorithms will remain forever and will form the basis for future developments.', metadata={'source': 'C:\\\\Users\\\\user\\\\Desktop\\\\AutoGPT\\\\data\\\\DSML.pdf'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_similar_docs(query, k=2, score = False):\n",
    "    if score:\n",
    "        similar_docs = index.similarity_search_with_score(query, k=k)\n",
    "    else:\n",
    "        similar_docs= index.similarity_search(query, k=k)\n",
    "    return similar_docs\n",
    "\n",
    "query = 'What is Datascience?'\n",
    "similar_docs = get_similar_docs(query)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquestion_answering\u001b[39;00m \u001b[39mimport\u001b[39;00m load_qa_chain\n\u001b[1;32m----> 2\u001b[0m chain \u001b[39m=\u001b[39m load_qa_chain(llm, chain_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstuff\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_answer\u001b[39m(query):\n\u001b[0;32m      5\u001b[0m     similar_docs \u001b[39m=\u001b[39m get_similar_docs(query)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "def get_answer(query):\n",
    "    similar_docs = get_similar_docs(query)\n",
    "    answer = chain.run(input_documents = similar_docs, question = query)\n",
    "    return answer\n",
    "\n",
    "query = \"What is linear regression?\"\n",
    "get_answer(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
